{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* 1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* 2. Apply a distortion correction to raw images.\n",
    "* 3. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* 4. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* 5. Detect lane pixels and fit to find the lane boundary.\n",
    "* 6. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* 7. Warp the detected lane boundaries back onto the original image.\n",
    "* 8. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import Modules & My function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib qt\n",
    "\n",
    "# Sobel threshold function (direction = 'x' or 'y')\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "\n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    grad_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    \n",
    "    return grad_binary\n",
    "\n",
    "# Sobel magnitude threshold function (mag = sqrt(x^2 + y^2))\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    magnitude_sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    scaled_sobel = np.uint8(255*magnitude_sobel/np.max(magnitude_sobel))\n",
    "\n",
    "    mag_binary = np.zeros_like(scaled_sobel)\n",
    "    mag_binary[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "    \n",
    "    return mag_binary\n",
    "\n",
    "# Direction threshold function (direction angle = artan2(y, x))\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "\n",
    "    dir_binary = np.zeros_like(absgraddir)\n",
    "    dir_binary[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "    \n",
    "    return dir_binary\n",
    "\n",
    "# HSV color threshold function\n",
    "def hsv_color_threshold(img, h_thresh=(130,255), s_thresh=(130,255), v_thresh=(130,255)):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    h_channel = hsv[:,:,0]\n",
    "    s_channel = hsv[:,:,1]\n",
    "    v_channel = hsv[:,:,2]\n",
    "    \n",
    "    # Threshold color channel\n",
    "    h_binary = np.zeros_like(h_channel)\n",
    "    h_binary[(h_channel >= h_thresh[0]) & (h_channel <= h_thresh[1])] = 1\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    v_binary = np.zeros_like(v_channel)\n",
    "    v_binary[(v_channel >= v_thresh[0]) & (v_channel <= v_thresh[1])] = 1\n",
    "    \n",
    "    return h_binary, s_binary, v_binary\n",
    "\n",
    "# HLS color threshold function\n",
    "def hls_color_threshold(img, h_thresh=(130,255), l_thresh=(130,255), s_thresh=(130,255)):\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # Threshold color channel\n",
    "    h_binary = np.zeros_like(h_channel)\n",
    "    h_binary[(h_channel >= h_thresh[0]) & (h_channel <= h_thresh[1])] = 1\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh[0]) & (l_channel <= l_thresh[1])] = 1\n",
    "    \n",
    "    return h_binary, l_binary, s_binary\n",
    "\n",
    "# LAB color threshold function\n",
    "def lab_color_threshold(img, l_thresh=(130,255), a_thresh=(130,255), b_thresh=(130,255)):\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    lab = cv2.medianBlur(lab, 5)\n",
    "    l_channel = lab[:,:,0]\n",
    "    a_channel = lab[:,:,1]\n",
    "    b_channel = lab[:,:,2]\n",
    "    \n",
    "    # Threshold color channel\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= l_thresh[0]) & (l_channel <= l_thresh[1])] = 1\n",
    "    a_binary = np.zeros_like(a_channel)\n",
    "    a_binary[(a_channel >= a_thresh[0]) & (a_channel <= a_thresh[1])] = 1\n",
    "    b_binary = np.zeros_like(b_channel)\n",
    "    b_binary[(b_channel >= b_thresh[0]) & (b_channel <= b_thresh[1])] = 1\n",
    "    \n",
    "    return l_binary, a_binary, b_binary\n",
    "\n",
    "# binary threshold function (In this project, I used Sobelx, hls_s_channel and hsv_v_channel)\n",
    "def binary_threshold(img):\n",
    "    ksize = 15\n",
    "    \n",
    "    # Take gardient threshold value\n",
    "    grad_x_binary = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=(20, 255))\n",
    "    grad_y_binary = abs_sobel_thresh(img, orient='y', sobel_kernel=ksize, thresh=(20, 255))\n",
    "    mag_binary = mag_thresh(img, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
    "    dir_binary = dir_threshold(img, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
    "    \n",
    "    # Take color threshold value\n",
    "    hls_h_binary, hls_l_binary, hls_s_binary = hls_color_threshold(img,(130,255),(100,255),(170,255))\n",
    "    hsv_h_binary, hsv_s_binary, hsv_v_binary = hsv_color_threshold(img,(130,255),(130,255),(170,255)) #200\n",
    "    lab_l_binary, lab_a_binary, lab_b_binary = lab_color_threshold(img,(130,255),(130,255),(130,255))\n",
    "    \n",
    "    combined = np.zeros_like(hls_s_binary)\n",
    "\n",
    "    # ('sobel x' or 'hls_s_bin') and 'hsv_v_bin' <- Overlap condition\n",
    "    combined[((grad_x_binary == 1) | (hls_s_binary == 1)) & (hsv_v_binary == 1)] = 1\n",
    "    \n",
    "    return combined\n",
    "\n",
    "# Perspective transform function\n",
    "def warpImage(img, img_size, unwarp = False):\n",
    "    # get 'src' and 'dst' value. (according to img_size, region is changed)\n",
    "    # take polygon area (ROI)\n",
    "    src = np.float32(\n",
    "       [[(img_size[0]/2)-65, (img_size[1]/2)+100],\n",
    "        [(img_size[0]/2)+65, (img_size[1]/2)+100],\n",
    "        [(img_size[0]*5/6)+60, img_size[1]],\n",
    "        [(img_size[0]/6)-60, img_size[1]]])\n",
    "    \n",
    "    dst = np.float32(\n",
    "       [[(img_size[0]/4), 0],\n",
    "        [(img_size[0]*3/4), 0],\n",
    "        [(img_size[0]*3/4), img_size[1]],\n",
    "        [(img_size[0]/4), img_size[1]]])\n",
    "    \n",
    "    # Using perspective transform function in opencv\n",
    "    # To back onto original image, 'unwarp = True' and change parameter 'src' and 'dst'\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    revM = cv2.getPerspectiveTransform(dst, src)\n",
    "    if unwarp == False :\n",
    "        # warp the image\n",
    "        warped_img = cv2.warpPerspective(img, M, img_size)\n",
    "    else :\n",
    "        warped_img = cv2.warpPerspective(img, revM, img_size)\n",
    "    \n",
    "    return src, warped_img\n",
    "\n",
    "# Polynomial fitting function (out_img is maked as seperately left and right lines)\n",
    "def fit_polynomial(img, binary_warped):\n",
    "    \n",
    "    # global variable for polynomial fitting\n",
    "    global prior_find\n",
    "    global first_time\n",
    "    global left_fit\n",
    "    global right_fit\n",
    "        \n",
    "    # Find our lane pixels first\n",
    "    if first_time == True:\n",
    "        print('slidig window')\n",
    "        leftx, lefty, rightx, righty, out_img  = find_lane_pixels(binary_warped)\n",
    "    else:\n",
    "        print('prior search')\n",
    "        leftx, lefty, rightx, righty, out_img = prior_search(binary_warped, left_fit, right_fit)\n",
    "        if ((len(leftx) == 0)|(len(rightx)==0)|(len(lefty)==0)|(len(righty)==0)):\n",
    "            prior_find = False\n",
    "        print(prior_find)\n",
    "        if prior_find == False:\n",
    "            print('Not found lanes, take slidig window')\n",
    "            leftx, lefty, rightx, righty, out_img  = find_lane_pixels(binary_warped)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            cv2.imwrite('error_image.jpg', img)\n",
    "    \n",
    "    # Using polyfit function, take coefficient of polynominal\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        prior_find = True\n",
    "        first_time = False\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        prior_find = False\n",
    "\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[lefty, leftx] = [255, 0, 0]\n",
    "    out_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    return left_fit, right_fit, left_fitx, right_fitx, ploty, out_img\n",
    "\n",
    "def prior_search(binary_warped, left_fit, right_fit):\n",
    "\n",
    "    margin = 100\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "\n",
    "    left_lane_inds = ((nonzerox > ((left_fit[0]*nonzeroy**2 + left_fit[1]*nonzeroy + left_fit[2])-margin)) &\n",
    "                      (nonzerox < ((left_fit[0]*nonzeroy**2 + left_fit[1]*nonzeroy + left_fit[2])+margin)))\n",
    "    right_lane_inds = ((nonzerox > ((right_fit[0]*nonzeroy**2 + right_fit[1]*nonzeroy + right_fit[2])-margin)) &\n",
    "                       (nonzerox < ((right_fit[0]*nonzeroy**2 + right_fit[1]*nonzeroy + right_fit[2])+margin)))\n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "    \n",
    "    \n",
    "\n",
    "# Fining lane pixels function (window search and prior search)\n",
    "def find_lane_pixels(binary_warped):\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 70\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 40\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### TO-DO: Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current - margin  # Update this\n",
    "        win_xleft_high = leftx_current + margin  # Update this\n",
    "        win_xright_low = rightx_current - margin  # Update this\n",
    "        win_xright_high = rightx_current + margin  # Update this\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low), (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low), (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:\n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n",
    "def complete_img(img, mtx, dist):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    # Distortion Correction to 'img'\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # To take binary images, I use binary_threshold() that was written above section.\n",
    "    binary_img = binary_threshold(undist)\n",
    "    \n",
    "    # For perspective transform, I add the warpImage() function\n",
    "    src, warped_img = warpImage(binary_img, img_size)\n",
    "    \n",
    "    left_fit, right_fit, left_fitx, right_fitx, ploty, out_img = fit_polynomial(img, warped_img)\n",
    "        \n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    y_eval = np.max(ploty)\n",
    "    center_fit = np.mean([left_fit,right_fit],axis =0)\n",
    "    center_fitx = np.mean([left_fitx,right_fitx],axis =0)\n",
    "\n",
    "    left_curverad = ((1+(2*left_fit[0]*y_eval*ym_per_pix+left_fit[1])**2)**(3/2))/np.absolute(2*left_fit[0])  ## Implement the calculation of the left line here\n",
    "    right_curverad = ((1+(2*right_fit[0]*y_eval*ym_per_pix+right_fit[1])**2)**(3/2))/np.absolute(2*right_fit[0])  ## Implement the calculation of the right line here\n",
    "    \n",
    "    unwarp_img = np.zeros((warped_img.shape[0], warped_img.shape[1],3), dtype=np.uint8)\n",
    "    \n",
    "    left_lane = np.dstack([left_fitx, ploty])\n",
    "    right_lane = np.dstack([right_fitx, ploty])\n",
    "    center_lane = np.dstack([center_fitx, ploty])\n",
    "    cv2.polylines(unwarp_img, np.int32([left_lane]), False, (255, 0, 0),thickness=40)\n",
    "    cv2.polylines(unwarp_img, np.int32([right_lane]), False, (0, 0, 255),thickness=40 )\n",
    "    \n",
    "    rev_right_lane = np.dstack([np.flip(right_fitx), np.flip(ploty)])\n",
    "    lane_polygon = np.hstack((left_lane, rev_right_lane))\n",
    "    \n",
    "    cv2.fillPoly(unwarp_img, np.int32(lane_polygon), (0, 255, 0))\n",
    "    cv2.polylines(unwarp_img, np.int32([center_lane]), False, (100, 0, 255),thickness=10)\n",
    "    center_cruverad = ((1+(2*center_fit[0]*y_eval*ym_per_pix+center_fit[1])**2)**(3/2))/np.absolute(2*center_fit[0])  ## Implement the calculation of the left line here\n",
    "    center_cruverad = np.int32(center_cruverad)\n",
    "    \n",
    "    center_pointx = center_fit[0]*y_eval**2 + center_fit[1]*y_eval + center_fit[2]\n",
    "    offset = round((center_pointx - img_size[0]/2)*xm_per_pix, 2)\n",
    "    \n",
    "    curv_str1 = 'Radius of Curvature = ' + str(center_cruverad) + 'm'\n",
    "    curv_str2 = 'Vehicle is '+str(offset)+'m'+' left of center'\n",
    "    curv_str3 = 'left side (+) / right side (-)'\n",
    "    \n",
    "    # Warp reversely the image that include drawing lane lines\n",
    "    src, unwarp_img = warpImage(unwarp_img, img_size, True)\n",
    "    \n",
    "    add_img = cv2.addWeighted(undist, 1, unwarp_img, 0.3, 0)\n",
    "    \n",
    "    cv2.putText(add_img, curv_str1, (50,40), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (255,255,255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(add_img, curv_str2, (50,85), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (255,255,255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(add_img, curv_str3, (50,125), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    return add_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Camera Callibration (for chessboard)\n",
    "* Undistort and Perspective Transform\n",
    "* Input images PATH = /camera_cal\n",
    "* ouput images PATH = /output_images/01_camera_cal\n",
    "* The file names of the input and the output image were made to match\n",
    "* If corners is not found, perspective transform of image will not take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chessboard size = 6*9\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Get objpoints and imgpoints to apply calibrateCamera() class\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray,(9,6),None)\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# Camera Calibration using objpoints and imgpoints\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "offset = 100\n",
    "nx = 9\n",
    "ny = 6\n",
    "# Saving calibration parameter by using pickle\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"] = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open( \"calibration.p\", \"wb\" ) )\n",
    "\n",
    "# Undistortion and Perspective transform of chessboard image\n",
    "# If corner is not found, only undistort() class will use\n",
    "# because perspective transform need corners points\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray,(9,6),None)\n",
    "    # If found, undistort and warp image\n",
    "    if ret == True:\n",
    "        # img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "        src = np.float32([corners[0], corners[nx-1], corners[-1], corners[-nx]])\n",
    "        dst = np.float32([[offset, offset], [img_size[0]-offset, offset], \n",
    "                                     [img_size[0]-offset, img_size[1]-offset], \n",
    "                                     [offset, img_size[1]-offset]])\n",
    "\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        undist = cv2.warpPerspective(undist, M, img_size)\n",
    "    # If not found, only undistort image not perspective transform\n",
    "    else:\n",
    "        undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    \n",
    "    filename = os.path.basename(fname)\n",
    "    cv2.imwrite('output_images/01_camera_cal/' + filename, undist)\n",
    "    cv2.imshow('warped', undist)\n",
    "    cv2.waitKey(500)\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distortion correction to raw images\n",
    "* In this pipeline, raw images(/test_images) will be undistorted\n",
    "* Input images PATH = /test_images\n",
    "* Output images PATH = /output_images/02_undistort_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load calibration parameter(mtx, dist) from pickle file\n",
    "dist_pickle = pickle.load( open( \"calibration.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "# Load imgae file using glob()\n",
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Distortion Correction to 'img'\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(undist)\n",
    "    ax2.set_title('Undistorted Image', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    filename = os.path.basename(fname)\n",
    "    \n",
    "    # save the images\n",
    "    plt.savefig('output_images/02_undistort_images/'+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create binary image\n",
    "* Using color & gradient method\n",
    "* Input images PATH = /test_images\n",
    "* Output Images PATH = /output_images/03_binary_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    comined_binary = binary_threshold(img)\n",
    "    \n",
    "    # Plot the result\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original image', fontsize=40)\n",
    "\n",
    "    ax2.imshow(comined_binary, cmap='gray')\n",
    "    ax2.set_title('Combined Binary', fontsize=40)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "    filename = os.path.basename(fname)\n",
    "    \n",
    "    # save the images\n",
    "    plt.savefig('output_images/03_binary_images/'+filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ############################## Thresh hold test \n",
    "\n",
    "\n",
    "# images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "# for fname in images:\n",
    "#     img = cv2.imread(fname)\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img_size = (img.shape[1], img.shape[0])\n",
    "#     src, warp_img = warpImage(img, img_size)\n",
    "#     ksize = 15\n",
    "#     kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
    "    \n",
    "#     grad_x_binary = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=(20, 255))\n",
    "# #     grad_x_binary = cv2.morphologyEx(grad_x_binary, cv2.MORPH_OPEN, kernel)\n",
    "#     grad_y_binary = abs_sobel_thresh(img, orient='y', sobel_kernel=ksize, thresh=(20, 255))\n",
    "#     mag_binary = mag_thresh(img, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
    "#     dir_binary = dir_threshold(img, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
    "\n",
    "    \n",
    "#     hls_h_binary, hls_l_binary, hls_s_binary = hls_color_threshold(img,(130,255),(100,255),(170,255))\n",
    "#     hsv_h_binary, hsv_s_binary, hsv_v_binary = hsv_color_threshold(img,(130,255),(130,255),(200,255))\n",
    "#     lab_l_binary, lab_a_binary, lab_b_binary = lab_color_threshold(img,(100,255),(130,255),(130,255))\n",
    "    \n",
    "#     combined = np.zeros_like(hls_s_binary)\n",
    "# #     combined[((grad_x_binary == 1) | (hls_s_binary == 1)) & (hsv_v_binary == 1)] = 1\n",
    "\n",
    "#     combined[((grad_x_binary == 1) | ((hls_s_binary ==1) &(hsv_v_binary == 1)))] = 1\n",
    "    \n",
    "#     # Plot the result\n",
    "#     f, ([ax1, ax2, ax3], [ax4, ax5, ax6]) = plt.subplots(2, 3, figsize=(24, 9))\n",
    "#     f.tight_layout()\n",
    "\n",
    "#     ax1.imshow(grad_x_binary, cmap='gray')\n",
    "#     ax1.set_title('grad_x_binary', fontsize=40)\n",
    "    \n",
    "#     ax2.imshow(hls_s_binary, cmap='gray')\n",
    "#     ax2.set_title('hls_s_binary', fontsize=40)\n",
    "\n",
    "#     ax3.imshow(hsv_v_binary, cmap='gray')\n",
    "#     ax3.set_title('hsv_v_binary', fontsize=40)\n",
    "    \n",
    "#     ax4.imshow(lab_l_binary, cmap='gray')\n",
    "#     ax4.set_title('lab_l_binary', fontsize=40)\n",
    "    \n",
    "#     ax5.imshow(lab_a_binary, cmap='gray')\n",
    "#     ax5.set_title('lab_a_binary', fontsize=40)    \n",
    "    \n",
    "#     ax6.imshow(combined, cmap='gray')\n",
    "#     ax6.set_title('combined', fontsize=40)    \n",
    "    \n",
    "#     plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Perspective transform (bird-eye view)\n",
    "* perspective transform image as ROI\n",
    "* Before perpective transforming, image is undistorted and binarized\n",
    "* Input images PATH = /test_images\n",
    "* Output Images PATH = /output_images/04_perspective_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load calibration parameter(mtx, dist) from pickle file\n",
    "dist_pickle = pickle.load( open( \"calibration.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "# Load imgae file using glob()\n",
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    # Distortion Correction to 'img'\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # To take binary images, I use binary_threshold() that was written above section.\n",
    "    binary_img = binary_threshold(undist)\n",
    "    \n",
    "    # For perspective transform, I add the warpImage() function\n",
    "    src, warped_img = warpImage(undist, img_size)\n",
    "\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(undist)\n",
    "    ax1.set_title('Image ROI', fontsize=40)\n",
    "    x = [src[0][0],src[1][0],src[2][0],src[3][0],src[0][0]]\n",
    "    y = [src[0][1],src[1][1],src[2][1],src[3][1],src[0][1]]\n",
    "    ax1.plot(x, y, color='#33cc99', alpha=0.4, linewidth=3, solid_capstyle='round', zorder=2)\n",
    "    ax2.imshow(warped_img, cmap='gray')\n",
    "    ax2.set_title('warped image', fontsize=40)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    filename = os.path.basename(fname)\n",
    "    \n",
    "    # save the images\n",
    "    plt.savefig('output_images/04_perspective_transform/'+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detect lane pixel and fitting curve\n",
    "* Detect left and light lane line pixcels using histogram\n",
    "* Fitting a polynomial to lane lines\n",
    "* Input images PATH = /test_images\n",
    "* Output Images PATH = /output_images/05_pixelandfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "# Load calibration parameter(mtx, dist) from pickle file\n",
    "dist_pickle = pickle.load( open( \"calibration.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    # Distortion Correction to 'img'\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # To take binary images, I use binary_threshold() that was written above section.\n",
    "    binary_img = binary_threshold(undist)\n",
    "    \n",
    "    # For perspective transform, I add the warpImage() function\n",
    "    src, warped_img = warpImage(binary_img, img_size)\n",
    "    \n",
    "    left_fit, right_fit, left_fitx, right_fitx, ploty, out_img = fit_polynomial(warped_img)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(warped_img, cmap ='gray')\n",
    "    ax1.set_title('warped bin image', fontsize=40)\n",
    "    ax2.imshow(out_img)\n",
    "    ax2.plot(left_fitx, ploty, color='yellow')\n",
    "    ax2.plot(right_fitx, ploty, color='yellow')\n",
    "    ax2.set_title('lane pixels and fitting', fontsize=40)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    filename = os.path.basename(fname)\n",
    "    \n",
    "    # save the images\n",
    "    plt.savefig('output_images/05_detect_and_fitting/'+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 & 7. Determine the curvature and offset of the lanes\n",
    "* Caculate curvature and offset of the lanes\n",
    "* Input images PATH = /test_images\n",
    "* Output Images PATH = /output_images/06_07_complete_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "# Load calibration parameter(mtx, dist) from pickle file\n",
    "dist_pickle = pickle.load( open( \"calibration.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    prior_find = False\n",
    "    first_time = True\n",
    "    \n",
    "    # Call image process function\n",
    "    # Init image -> Undistort -> Binary -> Warp -> Find lanes -> Unwarp\n",
    "    result_img = complete_img(img, mtx, dist)\n",
    "    \n",
    "    plt.figure(figsize=(24, 9))\n",
    "    plt.imshow(result_img)\n",
    "    plt.title('compelete image', fontsize=40)\n",
    "#     plt.text(50, 20,curv_str, fontsize = 20, color='white', \n",
    "#              horizontalalignment='left', verticalalignment='top')\n",
    "    \n",
    "    filename = os.path.basename(fname)\n",
    "    \n",
    "    # save the images\n",
    "    plt.savefig('output_images/06_07_complete_images/'+filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Output visual display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_img_process(img):\n",
    "   \n",
    "    # Load calibration parameter(mtx, dist) from pickle file\n",
    "    dist_pickle = pickle.load( open( \"calibration.p\", \"rb\" ) )\n",
    "    mtx = dist_pickle[\"mtx\"]\n",
    "    dist = dist_pickle[\"dist\"]\n",
    "    \n",
    "    result_img = complete_img(img, mtx, dist)\n",
    "        \n",
    "    return result_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|          | 0/125 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slidig window\n",
      "Moviepy - Building video output_videos/project_video.mp4.\n",
      "Moviepy - Writing video output_videos/project_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   2%|▏         | 2/125 [00:00<00:15,  8.14it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   2%|▏         | 3/125 [00:00<00:20,  5.96it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   3%|▎         | 4/125 [00:00<00:22,  5.32it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   4%|▍         | 5/125 [00:00<00:24,  4.96it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   5%|▍         | 6/125 [00:01<00:24,  4.85it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   6%|▌         | 7/125 [00:01<00:24,  4.80it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   6%|▋         | 8/125 [00:01<00:25,  4.67it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   7%|▋         | 9/125 [00:01<00:25,  4.56it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   8%|▊         | 10/125 [00:02<00:25,  4.55it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   9%|▉         | 11/125 [00:02<00:25,  4.45it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  10%|▉         | 12/125 [00:02<00:25,  4.42it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  10%|█         | 13/125 [00:02<00:25,  4.47it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  11%|█         | 14/125 [00:03<00:25,  4.43it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  12%|█▏        | 15/125 [00:03<00:24,  4.44it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  13%|█▎        | 16/125 [00:03<00:24,  4.45it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  14%|█▎        | 17/125 [00:03<00:24,  4.43it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  14%|█▍        | 18/125 [00:03<00:24,  4.37it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  15%|█▌        | 19/125 [00:04<00:24,  4.32it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  16%|█▌        | 20/125 [00:04<00:24,  4.29it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  17%|█▋        | 21/125 [00:04<00:24,  4.29it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  18%|█▊        | 22/125 [00:04<00:24,  4.25it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  18%|█▊        | 23/125 [00:05<00:23,  4.29it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  19%|█▉        | 24/125 [00:05<00:23,  4.28it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  20%|██        | 25/125 [00:05<00:23,  4.34it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  21%|██        | 26/125 [00:05<00:22,  4.47it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  22%|██▏       | 27/125 [00:05<00:21,  4.48it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  22%|██▏       | 28/125 [00:06<00:21,  4.59it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  23%|██▎       | 29/125 [00:06<00:20,  4.69it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  24%|██▍       | 30/125 [00:06<00:20,  4.62it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  25%|██▍       | 31/125 [00:06<00:20,  4.55it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  26%|██▌       | 32/125 [00:07<00:20,  4.55it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  27%|██▋       | 34/125 [00:07<00:19,  4.71it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  28%|██▊       | 35/125 [00:07<00:19,  4.67it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  29%|██▉       | 36/125 [00:07<00:19,  4.67it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  30%|██▉       | 37/125 [00:08<00:18,  4.79it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  31%|███       | 39/125 [00:08<00:17,  4.93it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  33%|███▎      | 41/125 [00:08<00:16,  5.07it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  34%|███▍      | 43/125 [00:09<00:16,  5.08it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  35%|███▌      | 44/125 [00:09<00:16,  4.86it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  37%|███▋      | 46/125 [00:09<00:15,  4.97it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  38%|███▊      | 48/125 [00:10<00:15,  5.02it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  40%|████      | 50/125 [00:10<00:14,  5.04it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  41%|████      | 51/125 [00:10<00:14,  5.05it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  42%|████▏     | 52/125 [00:11<00:14,  4.99it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  42%|████▏     | 53/125 [00:11<00:14,  4.92it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  43%|████▎     | 54/125 [00:11<00:14,  4.86it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  44%|████▍     | 55/125 [00:11<00:14,  4.91it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  45%|████▍     | 56/125 [00:11<00:14,  4.90it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  46%|████▋     | 58/125 [00:12<00:13,  4.91it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  47%|████▋     | 59/125 [00:12<00:13,  4.93it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  48%|████▊     | 60/125 [00:12<00:13,  4.93it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  49%|████▉     | 61/125 [00:12<00:13,  4.88it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  50%|█████     | 63/125 [00:13<00:12,  4.95it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  51%|█████     | 64/125 [00:13<00:12,  4.98it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  52%|█████▏    | 65/125 [00:13<00:12,  4.90it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  54%|█████▎    | 67/125 [00:14<00:11,  4.94it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  54%|█████▍    | 68/125 [00:14<00:11,  4.88it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  55%|█████▌    | 69/125 [00:14<00:11,  4.91it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  56%|█████▌    | 70/125 [00:14<00:11,  4.90it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  57%|█████▋    | 71/125 [00:14<00:11,  4.88it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  58%|█████▊    | 72/125 [00:15<00:10,  4.88it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  58%|█████▊    | 73/125 [00:15<00:10,  4.92it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  59%|█████▉    | 74/125 [00:15<00:10,  4.87it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  60%|██████    | 75/125 [00:15<00:10,  4.86it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  61%|██████    | 76/125 [00:15<00:10,  4.90it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  62%|██████▏   | 77/125 [00:16<00:09,  4.91it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  63%|██████▎   | 79/125 [00:16<00:09,  4.98it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  64%|██████▍   | 80/125 [00:16<00:09,  4.88it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  65%|██████▍   | 81/125 [00:17<00:09,  4.80it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  66%|██████▌   | 82/125 [00:17<00:08,  4.84it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  66%|██████▋   | 83/125 [00:17<00:08,  4.80it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  67%|██████▋   | 84/125 [00:17<00:08,  4.80it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  68%|██████▊   | 85/125 [00:17<00:08,  4.76it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  69%|██████▉   | 86/125 [00:18<00:08,  4.86it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  70%|██████▉   | 87/125 [00:18<00:07,  4.85it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  71%|███████   | 89/125 [00:18<00:07,  4.95it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  72%|███████▏  | 90/125 [00:18<00:07,  4.98it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  73%|███████▎  | 91/125 [00:19<00:06,  4.86it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  74%|███████▎  | 92/125 [00:19<00:06,  4.88it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  74%|███████▍  | 93/125 [00:19<00:06,  4.90it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  76%|███████▌  | 95/125 [00:19<00:06,  4.84it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  77%|███████▋  | 96/125 [00:20<00:05,  4.91it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  78%|███████▊  | 97/125 [00:20<00:05,  4.93it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  78%|███████▊  | 98/125 [00:20<00:05,  4.83it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  79%|███████▉  | 99/125 [00:20<00:05,  4.82it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  80%|████████  | 100/125 [00:20<00:05,  4.87it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  82%|████████▏ | 102/125 [00:21<00:04,  4.91it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  83%|████████▎ | 104/125 [00:21<00:04,  4.98it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  85%|████████▍ | 106/125 [00:22<00:03,  4.94it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  86%|████████▌ | 107/125 [00:22<00:03,  4.97it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  86%|████████▋ | 108/125 [00:22<00:03,  4.96it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  87%|████████▋ | 109/125 [00:22<00:03,  4.91it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  88%|████████▊ | 110/125 [00:22<00:03,  4.88it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  89%|████████▉ | 111/125 [00:23<00:02,  4.91it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  90%|████████▉ | 112/125 [00:23<00:02,  4.92it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  90%|█████████ | 113/125 [00:23<00:02,  4.91it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  91%|█████████ | 114/125 [00:23<00:02,  4.89it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  92%|█████████▏| 115/125 [00:23<00:02,  4.89it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  94%|█████████▎| 117/125 [00:24<00:01,  4.95it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  94%|█████████▍| 118/125 [00:24<00:01,  4.91it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  95%|█████████▌| 119/125 [00:24<00:01,  4.88it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n",
      "prior search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  96%|█████████▌| 120/125 [00:24<00:01,  4.92it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  98%|█████████▊| 122/125 [00:25<00:00,  4.85it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  98%|█████████▊| 123/125 [00:25<00:00,  4.80it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:  99%|█████████▉| 124/125 [00:25<00:00,  4.77it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t: 100%|██████████| 125/125 [00:26<00:00,  4.80it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior search\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_videos/project_video.mp4\n",
      "CPU times: user 46.5 s, sys: 6.84 s, total: 53.3 s\n",
      "Wall time: 26.8 s\n"
     ]
    }
   ],
   "source": [
    "video_output = 'output_videos/project_video.mp4'\n",
    "\n",
    "prior_find = False\n",
    "first_time = True\n",
    "\n",
    "clip1 = VideoFileClip('project_video.mp4').subclip(0,5)\n",
    "video_clip = clip1.fl_image(video_img_process)\n",
    "%time video_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_videos/project_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Video\n",
    "* Fail....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video_output = 'output_videos/challenge_video.mp4'\n",
    "\n",
    "# prior_find = False\n",
    "# first_time = True\n",
    "\n",
    "# clip1 = VideoFileClip('challenge_video.mp4').subclip(0,5)\n",
    "# video_clip = clip1.fl_image(video_img_process)\n",
    "# %time video_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_videos/challenge_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(video_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## challenge video trouble shooting\n",
    "* Fail...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('error_image.jpg')\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "# # Distortion Correction to 'img'\n",
    "# undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "# # To take binary images, I use binary_threshold() that was written above section.\n",
    "# ksize = 15\n",
    "\n",
    "# # Take gardient threshold value\n",
    "# grad_x_binary = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=(20, 255))\n",
    "# grad_y_binary = abs_sobel_thresh(img, orient='y', sobel_kernel=ksize, thresh=(20, 255))\n",
    "# mag_binary = mag_thresh(img, sobel_kernel=ksize, mag_thresh=(30, 100))\n",
    "# dir_binary = dir_threshold(img, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
    "\n",
    "# # Take color threshold value\n",
    "# hls_h_binary, hls_l_binary, hls_s_binary = hls_color_threshold(img,(130,255),(100,255),(170,255))\n",
    "# hsv_h_binary, hsv_s_binary, hsv_v_binary = hsv_color_threshold(img,(130,255),(130,255),(170,255))\n",
    "# lab_l_binary, lab_a_binary, lab_b_binary = lab_color_threshold(img,(130,255),(130,255),(130,255))\n",
    "\n",
    "# combined = np.zeros_like(hls_s_binary)\n",
    "\n",
    "# # ('sobel x' or 'hls_s_bin') and 'hsv_v_bin' <- Overlap condition\n",
    "# combined[((grad_x_binary == 1) | (hls_s_binary == 1)) & (hsv_v_binary == 1)] = 1\n",
    "\n",
    "# # For perspective transform, I add the warpImage() function\n",
    "# src, warped_img = warpImage(binary_img, img_size)\n",
    "\n",
    "\n",
    "# # Plot the result\n",
    "# f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(24, 9))\n",
    "# f.tight_layout()\n",
    "\n",
    "# ax1.imshow(grad_x_binary, cmap='gray')\n",
    "# ax1.set_title('grad_x_binary', fontsize=40)\n",
    "\n",
    "# ax2.imshow(hls_s_binary, cmap='gray')\n",
    "# ax2.set_title('hls_s_binary', fontsize=40)\n",
    "\n",
    "# ax3.imshow(hsv_v_binary, cmap='gray')\n",
    "# ax3.set_title('hsv_v_binary', fontsize=40)    \n",
    "\n",
    "# plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
